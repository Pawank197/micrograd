Micrograd is a repo i created for learning the fundamentals of a neural net training.

It is fully self-contained, meaning i haven't used any framework like pytorch or keras for anything.

# To Use It:
from enigne import Value, and wrap your inputs in the Value object and from nn.py file, use MLP class to create different no. of layers with different no. of neurons.

Inspired and Based on andrej karpathy's micrograd. 
